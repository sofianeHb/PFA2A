name: ML Pipeline

on:
  workflow_dispatch:
  push:
    branches:
      - main

jobs:
  ml_pipeline:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python 3.9.20
      uses: actions/setup-python@v4
      with:
        python-version: '3.9.20'
      
    - name: Install Graphviz
      run: |
          sudo apt-get update
          sudo apt-get install -y graphviz

    - name: Install DVC and dependencies
      run: |
        python -m pip install --upgrade pip
        pip uninstall -y protobuf
        pip install protobuf==3.19.6 --no-cache-dir
        pip install -r requirements.txt
        python -c "import google.protobuf; print('protobuf version:', google.protobuf.__version__)"

    - name: Pull data from DVC remote (if needed)
      run: dvc pull || echo "Pas de remote configur√© pour DVC."

    - name: Run data preprocessing
      run: |
        python data_preprocessing.py
        dvc add data/pneumonia_dataset.csv
        git add data/pneumonia_dataset.csv.dvc
        git config --global user.name "github-actions"
        git config --global user.email "action@github.com"
        git diff --quiet || git commit -m "Track dataset with DVC after preprocessing"

    - name: Split data
      run: |
        python train_test_split.py
        dvc add data/splits/train_split.csv
        dvc add data/splits/valid_split.csv
        dvc add data/splits/test_split.csv
        git add data/splits/*.dvc
        git diff --quiet || git commit -m "Track data splits with DVC"

    - name: Train model
      run: |
        python model_training.py
        dvc add -f outputs/models/Enhanced_model_V2.keras
        git add -f outputs/models/Enhanced_model_V2.keras.dvc
        git diff --quiet || git commit -m "Track trained model with DVC"

    - name: Evaluate model
      run: python model_evaluation.py

    - name: Validate model
      run: |
        python -c "
        import json
        with open('outputs/results/classification_report.json') as f:
            report = json.load(f)
        f1_normal = report['NORMAL']['f1-score']
        f1_pneumonia = report['PNEUMONIA']['f1-score']
        print(f'F1-score NORMAL: {f1_normal}')
        print(f'F1-score PNEUMONIA: {f1_pneumonia}')
        if f1_normal < 0.9 or f1_pneumonia < 0.9:
            print('Mod√®le rejet√© : F1-score trop bas')
        else:
            print('Mod√®le valid√© !')
        "
    - name: Afficher l'arborescence du r√©pertoire
      run: |
          sudo apt-get install -y tree
          echo "Arborescence du r√©pertoire courant :"
          tree -L 2  # Tu peux ajuster le niveau si besoin
      
    - name: Set up Ngrok and Run MLflow UI
      env:
          NGROK_AUTH_TOKEN: ${{ secrets.NGROK_AUTH_TOKEN }}
      run: |
            pip install pyngrok requests
            python -c "
            import os
            import time
            import subprocess
            from pyngrok import ngrok

            # Auth Ngrok
            ngrok.set_auth_token(os.environ['NGROK_AUTH_TOKEN'])

            # Lancer le serveur MLflow via subprocess
            mlflow_process = subprocess.Popen([
                'mlflow', 'ui',
                '--backend-store-uri', './mlruns',
                '--default-artifact-root', './mlruns',
                '--host', '0.0.0.0',
                '--port', '5000'
            ])

            # Attendre que le serveur d√©marre
            time.sleep(10)
            print('premier sleep termine')

            # Tunnel ngrok
            public_url = ngrok.connect(5000)
            print('\\n' + '='*50)
            print('üöÄ MLflow UI is available at:', public_url)
            print('='*50 + '\\n')
            time.sleep(300)
            

            # Arr√™ter les processus
            #mlflow_process.terminate()
            #ngrok.kill()
            "
    
    - name: Archive artifacts
      uses: actions/upload-artifact@v4
      with:
        name: model-artifacts
        path: |
          **/*.txt
          **/*.png
          **/*.csv
          **/*.keras
