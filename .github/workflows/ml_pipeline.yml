name: ML Pipeline

on:
  workflow_dispatch:
  push:
    branches:
      - main

jobs:
  ml_pipeline:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python 3.9.20
      uses: actions/setup-python@v4
      with:
        python-version: '3.9.20'
      

    - name: Install DVC and dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y graphviz
        python -m pip install --upgrade pip
        pip uninstall -y protobuf
        pip install protobuf==3.19.6 --no-cache-dir
        pip install -r requirements.txt
        python -c "import google.protobuf; print('protobuf version:', google.protobuf.__version__)"
    

    - name: Run data preprocessing
      run: |
        python data_preprocessing.py
        dvc add data/pneumonia_dataset.csv
        git add data/pneumonia_dataset.csv.dvc
        git config --global user.name "github-actions"
        git config --global user.email "action@github.com"
        git diff --quiet || git commit -m "Track dataset with DVC after preprocessing"

    - name: Split data
      run: |
        python train_test_split.py
        dvc add data/splits/train_split.csv
        dvc add data/splits/valid_split.csv
        dvc add data/splits/test_split.csv
        git add data/splits/*.dvc
        git diff --quiet || git commit -m "Track data splits with DVC"

    - name: Train model
      run: |
        python model_training.py
        dvc add -f outputs/models/Enhanced_model_V2.keras
        git add -f outputs/models/Enhanced_model_V2.keras.dvc
        git diff --quiet || git commit -m "Track trained model with DVC"

    - name: Evaluate model
      run: python model_evaluation.py

    - name: Validate model
      run: |
        python -c "
        import json
        with open('outputs/results/classification_report.json') as f:
            report = json.load(f)
        f1_normal = report['NORMAL']['f1-score']
        f1_pneumonia = report['PNEUMONIA']['f1-score']
        print(f'F1-score NORMAL: {f1_normal}')
        print(f'F1-score PNEUMONIA: {f1_pneumonia}')
        if f1_normal < 0.9 or f1_pneumonia < 0.9:
            print('ModÃ¨le rejetÃ© : F1-score trop bas')
        else:
            print('ModÃ¨le validÃ© !')
        "

    - name: Set up Ngrok and Run MLflow UI
      env:
        NGROK_AUTH_TOKEN: ${{ secrets.NGROK_AUTH_TOKEN }}
      run: |
        pip install pyngrok requests
        python -c "
        import os
        import time
        import subprocess
        from pyngrok import ngrok

        ngrok.set_auth_token(os.environ['NGROK_AUTH_TOKEN'])

        mlflow_process = subprocess.Popen([
            'mlflow', 'ui',
            '--backend-store-uri', './mlruns',
            '--default-artifact-root', './mlruns',
            '--host', '0.0.0.0',
            '--port', '5000'
        ])
        time.sleep(10)
        print('premier sleep terminÃ©')
        public_url = ngrok.connect(5000)
        print('\\n' + '='*50)
        print('ðŸš€ MLflow UI is available at:', public_url)
        print('='*50 + '\\n')
        time.sleep(10)
        "

    - name: Archive artifacts
      uses: actions/upload-artifact@v4
      with:
        name: model-artifacts
        path: |
          **/*.txt
          **/*.png
          **/*.csv
          **/*.keras

    - name: Upload MLflow logs
      uses: actions/upload-artifact@v4
      with:
        name: mlruns
        path: mlruns/

    - name: Upload Data directory
      uses: actions/upload-artifact@v4
      with:
        name: data
        path: data/

    - name: Upload Outputs directory
      uses: actions/upload-artifact@v4
      with:
        name: outputs
        path: outputs/
